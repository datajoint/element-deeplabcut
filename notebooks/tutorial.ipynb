{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DataJoint Element DeepLabCut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Interactively run the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The workflow requires a DeepLabCut project with labeled data.\n",
    "- If you don't have data, refer to [00-DataDownload](./00-DataDownload_Optional.ipynb) and [01-Configure](./01-Configure.ipynb).\n",
    "- For an overview of the schema, refer to [02-WorkflowStructure](02-WorkflowStructure_Optional.ipynb).\n",
    "- For a more automated approach, refer to [03-Automate](03-Automate_Optional.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the directory to load the local config, `dj_local_conf.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-04 16:31:58,365][INFO]: Connecting milagrosmarin@rds.datajoint.io:3306\n",
      "[2023-08-04 16:31:58,753][INFO]: Connected milagrosmarin@rds.datajoint.io:3306\n",
      "[2023-08-04 16:31:58,793][WARNING]: lab.Project and related tables will be removed in a future version of Element Lab. Please use the project schema.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.basename(os.getcwd())=='notebooks': os.chdir('..')\n",
    "\n",
    "import datajoint as dj\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# PATHS OF INPUT FILES: Extract abs and rel paths from .json file\n",
    "dj.conn()\n",
    "\n",
    "### DLC Project\n",
    "dlc_project_path_abs = Path(dj.config[\"custom\"][\"dlc_root_data_dir\"]) / Path(\n",
    "    dj.config[\"custom\"][\"current_project_folder\"]\n",
    ")  # use pathlib to join; abs path\n",
    "dlc_project_folder = Path(\n",
    "    dj.config[\"custom\"][\"current_project_folder\"]\n",
    ")  # relative path\n",
    "\n",
    "### Config file\n",
    "config_file_abs = dlc_project_path_abs / \"config.yaml\"  # abs path\n",
    "assert (\n",
    "    config_file_abs.exists()\n",
    "), \"Please check the that you have the Top_tracking folder\"\n",
    "\n",
    "### Labeled-data\n",
    "labeled_data_path_abs = dlc_project_path_abs / \"labeled-data\"\n",
    "labeled_files_abs = list(\n",
    "    list(labeled_data_path_abs.rglob(\"*\"))[1].rglob(\"*\")\n",
    ")  # substitute 'training_files'; absolute path\n",
    "labeled_files_rel = []\n",
    "for file in labeled_files_abs:\n",
    "    labeled_files_rel.append(\n",
    "        file.relative_to(dlc_project_path_abs)\n",
    "    )  # substitute 'training_files'; relative path\n",
    "\n",
    "\n",
    "from pipeline import lab, subject, session, train, model  # after creating json file\n",
    "\n",
    "# Empty the session in case of rerunning\n",
    "# session.Session.delete()\n",
    "# train.TrainingTask.delete()\n",
    "# train.TrainingParamSet.delete()\n",
    "# train.VideoSet.delete()\n",
    "\n",
    "# Insert some data in session and train tables\n",
    "# TO-DO: substitute lab.project by project schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(subject) + dj.Diagram(lab) + dj.Diagram(session) + dj.Diagram(model) + dj.Diagram(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.Subject()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject and Session tables\n",
    "subject.Subject.insert1(\n",
    "    dict(\n",
    "        subject=\"subject6\",\n",
    "        sex=\"F\",\n",
    "        subject_birth_date=\"2020-01-01\",\n",
    "        subject_description=\"hneih_E105\",\n",
    "    ),\n",
    "    skip_duplicates=True,\n",
    ")\n",
    "session_keys = [\n",
    "    dict(subject=\"subject6\", session_datetime=\"2021-06-02 14:04:22\"),\n",
    "    dict(subject=\"subject6\", session_datetime=\"2021-06-03 14:43:10\"),\n",
    "]\n",
    "\n",
    "session.Session.insert(session_keys, skip_duplicates=True)\n",
    "session.Session() & \"session_datetime > '2021-06-01 12:00:00'\" & \"subject='subject6'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Videoset tabley\n",
    "train.VideoSet.insert1({\"video_set_id\": 0}, skip_duplicates=True)\n",
    "\n",
    "# training_files = #['labeled-data/train1_trimmed/CollectedData_DataJoint.h5',\n",
    "#'labeled-data/train1_trimmed/CollectedData_DataJoint.csv']\n",
    "#'labeled-data/train1_trimmed/img00674.png'] #TO-DO: CHECK IF ALL THE PNGS ARE NECESSARY FOR TRAINING\n",
    "#'videos/train1.mp4']\n",
    "# for idx, filename in enumerate(training_files):\n",
    "for idx, filename in enumerate(labeled_files_rel):\n",
    "    train.VideoSet.File.insert1(\n",
    "        {\"video_set_id\": 0, \"file_id\": idx, \"file_path\": dlc_project_folder / filename},\n",
    "        skip_duplicates=True,\n",
    "    )  # Changed from + to /; #relative_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.VideoSet.File()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.list_schemas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.schema.drop()\n",
    "train.schema.drop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict the training interations to 5 modifying the default parameters in config.yaml\n",
    "paramset_idx = 0\n",
    "paramset_desc = \"First training test with DLC using shuffle 1 and maxiters = 5\"\n",
    "\n",
    "# default parameters\n",
    "with open(config_file_abs, \"rb\") as y:\n",
    "    config_params = yaml.safe_load(y)\n",
    "config_params.keys()\n",
    "\n",
    "# new parameters\n",
    "training_params = {\n",
    "    \"shuffle\": \"1\",\n",
    "    \"trainingsetindex\": \"0\",\n",
    "    \"maxiters\": \"5\",\n",
    "    \"scorer_legacy\": \"False\",  # For DLC ≤ v2.0, include scorer_legacy = True in params\n",
    "    \"maxiters\": \"5\",\n",
    "    \"multianimalproject\": \"False\",\n",
    "}\n",
    "config_params.update(training_params)\n",
    "\n",
    "train.TrainingParamSet.insert_new_params(\n",
    "    paramset_idx=paramset_idx, paramset_desc=paramset_desc, params=config_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainingTask table\n",
    "key = {\n",
    "    \"video_set_id\": 0,\n",
    "    \"paramset_idx\": 0,\n",
    "    \"training_id\": 1,\n",
    "    \"project_path\": dlc_project_folder,\n",
    "}\n",
    "train.TrainingTask.insert1(key, skip_duplicates=True)\n",
    "train.TrainingTask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelTraining:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.2.3...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1]],\n",
      " 'all_joints_names': ['Head', 'Tailbase'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 1,\n",
      " 'contrast': {'clahe': True,\n",
      "              'claheratio': 0.1,\n",
      "              'histeq': True,\n",
      "              'histeqratio': 0.1},\n",
      " 'convolution': {'edge': False,\n",
      "                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},\n",
      "                 'embossratio': 0.1,\n",
      "                 'sharpen': False,\n",
      "                 'sharpenratio': 0.3},\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Top_trackingAug3/Top_tracking_DataJoint95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/Users/milagros/Documents/DeepLabCut_testing/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Top_trackingAug3/Documentation_data-Top_tracking_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 2,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/Users/milagros/Documents/DeepLabCut_testing/Top_tracking-DataJoint-2023-08-03',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/Users/milagros/Documents/DeepLabCut_testing/Top_tracking-DataJoint-2023-08-03/dlc-models/iteration-0/Top_trackingAug3-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Batch Size is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ImageNet-pretrained resnet_50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 16:32:09.138337: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-08-04 16:32:09.350845: W tensorflow/c/c_api.cc:300] Operation '{name:'pose/locref_pred/block4/biases/Momentum/Assign' id:6191 op device:{requested: '', assigned: ''} def:{{{node pose/locref_pred/block4/biases/Momentum/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](pose/locref_pred/block4/biases/Momentum, pose/locref_pred/block4/biases/Momentum/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_iters overwritten as 5\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/Users/milagros/Documents/DeepLabCut_testing/Top_tracking-DataJoint-2023-08-03/dlc-models/iteration-0/Top_trackingAug3-trainset95shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'imgaug', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1]], 'all_joints_names': ['Head', 'Tailbase'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'contrast': {'clahe': True, 'claheratio': 0.1, 'histeq': True, 'histeqratio': 0.1, 'gamma': False, 'sigmoid': False, 'log': False, 'linear': False}, 'convolution': {'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]}, 'embossratio': 0.1, 'sharpen': False, 'sharpenratio': 0.3}, 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Top_trackingAug3/Top_tracking_DataJoint95shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'init_weights': '/Users/milagros/Documents/DeepLabCut_testing/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Top_trackingAug3/Documentation_data-Top_tracking_95shuffle1.pickle', 'min_input_size': 64, 'multi_stage': False, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 2, 'pos_dist_thresh': 17, 'project_path': '/Users/milagros/Documents/DeepLabCut_testing/Top_tracking-DataJoint-2023-08-03', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 16:32:13.682675: W tensorflow/core/kernels/queue_base.cc:277] _0_fifo_queue: Skipping cancelled enqueue attempt with queue not closed\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1378, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1361, in _run_fn\n",
      "    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1454, in _call_tf_sessionrun\n",
      "    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node fifo_queue_enqueue}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 83, in load_and_enqueue\n",
      "    sess.run(enqueue_op, feed_dict=food)\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 968, in run\n",
      "    result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1191, in _run\n",
      "    results = self._do_run(handle, final_targets, final_fetches,\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1371, in _do_run\n",
      "    return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1397, in _do_call\n",
      "    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Graph execution error:\n",
      "\n",
      "Detected at node 'fifo_queue_enqueue' defined at (most recent call last):\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "      app.start()\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "      handle._run()\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "      await result\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/var/folders/h8/_lx50k3d6qx586662kr066h40000gn/T/ipykernel_43888/556392206.py\", line 1, in <module>\n",
      "      train.ModelTraining.populate(display_progress=True)\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/datajoint/autopopulate.py\", line 241, in populate\n",
      "      error = self._populate1(key, jobs, **populate_kwargs)\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/datajoint/autopopulate.py\", line 292, in _populate1\n",
      "      make(dict(key), **(make_kwargs or {}))\n",
      "    File \"/Users/milagros/Documents/element-deeplabcut/element_deeplabcut/train.py\", line 312, in make\n",
      "      train_network(dlc_cfg_filepath, **train_network_kwargs)\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\", line 210, in train_network\n",
      "      train(\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 168, in train\n",
      "      batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      "    File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 69, in setup_preloading\n",
      "      enqueue_op = q.enqueue(placeholders_list)\n",
      "Node: 'fifo_queue_enqueue'\n",
      "Enqueue operation was cancelled\n",
      "\t [[{{node fifo_queue_enqueue}}]]\n",
      "\n",
      "Original stack trace for 'fifo_queue_enqueue':\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/h8/_lx50k3d6qx586662kr066h40000gn/T/ipykernel_43888/556392206.py\", line 1, in <module>\n",
      "    train.ModelTraining.populate(display_progress=True)\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/datajoint/autopopulate.py\", line 241, in populate\n",
      "    error = self._populate1(key, jobs, **populate_kwargs)\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/datajoint/autopopulate.py\", line 292, in _populate1\n",
      "    make(dict(key), **(make_kwargs or {}))\n",
      "  File \"/Users/milagros/Documents/element-deeplabcut/element_deeplabcut/train.py\", line 312, in make\n",
      "    train_network(dlc_cfg_filepath, **train_network_kwargs)\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\", line 210, in train_network\n",
      "    train(\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 168, in train\n",
      "    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 69, in setup_preloading\n",
      "    enqueue_op = q.enqueue(placeholders_list)\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 346, in enqueue\n",
      "    return gen_data_flow_ops.queue_enqueue_v2(\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 4068, in queue_enqueue_v2\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 795, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "  File \"/Users/milagros/miniconda3/envs/dlc_pip/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3814, in _create_op_internal\n",
      "    ret = Operation(\n",
      "\n",
      "ModelTraining: 100%|██████████| 1/1 [00:09<00:00,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([(0, 0, 1, 5, {'Task': 'Top_tracking', 'scorer': 'DataJoint', 'date': 'Aug3', 'multianimalproject': 'False', 'identity': None, 'project_path': '/Users/milagros/Documents/DeepLabCut_testing/Top_tracking-DataJoint-2023-08-03', 'video_sets': {'/Users/milagros/Documents/DeepLabCut_testing/test_data/Top_tracking-DataJoint-2023-08-03/videos/train1_trimmed.mp4': {'crop': '0, 500, 0, 500'}}, 'bodyparts': ['Head', 'Tailbase'], 'start': 0, 'stop': 1, 'numframes2pick': 5, 'skeleton': [['bodypart1', 'bodypart2'], ['objectA', 'bodypart3']], 'skeleton_color': 'black', 'pcutoff': 0.6, 'dotsize': 12, 'alphavalue': 0.7, 'colormap': 'rainbow', 'TrainingFraction': [0.95], 'iteration': 0, 'default_net_type': 'resnet_50', 'default_augmenter': 'default', 'snapshotindex': -1, 'batch_size': 8, 'cropping': False, 'x1': 0, 'x2': 640, 'y1': 277, 'y2': 624, 'corner2move2': [50, 50], 'move2corner': True, 'shuffle': '1', 'trainingsetindex': '0', 'maxiters': '5', 'scorer_legacy': 'False', 'modelprefix': '', 'train_fraction': 0.95, 'training_filelist_datajoint': ['/Users/milagros/Documents/DeepLabCut_testing/Top_tracking-DataJoint-2023-08-03/labeled-data/train1_trimmed/img0446.png', '/Users/milagros/Documents/DeepLabCut_testing/Top_tracking-DataJoint-2023-08-03/labeled-data/train1_trimmed/CollectedData_DataJoint.h5', '/Users/milagros/Documents/DeepLabCut_testing/Top_tracking-DataJoint-2023-08-03/labeled-data/train1_trimmed/img0482.png', '/Users/milagros/Documents/DeepLabCut_testing/Top_tracking-DataJoint-2023-08-03/labeled-data/train1_trimmed/CollectedData_DataJoint.csv', '/Users/milagros/Documents/DeepLabCut_testing/Top_tracking-DataJoint-2023-08-03/labeled-data/train1_trimmed/img1420.png', '/Users/milagros/Documents/DeepLabCut_testing/Top_tracking-DataJoint-2023-08-03/labeled-data/train1_trimmed/img0822.png', '/Users/milagros/Documents/DeepLabCut_testing/Top_tracking-DataJoint-2023-08-03/labeled-data/train1_trimmed/img1723.png']})],\n",
       "      dtype=[('video_set_id', '<i8'), ('paramset_idx', '<i8'), ('training_id', '<i8'), ('latest_snapshot', '<i8'), ('config_template', 'O')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.ModelTraining.populate(display_progress=True)\n",
    "train.ModelTraining.fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old notebook ----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# change to the upper level folder to detect dj_local_conf.json\n",
    "if os.path.basename(os.getcwd())=='notebooks': os.chdir('..')\n",
    "assert os.path.basename(os.getcwd())=='workflow-deeplabcut', (\"Please move to the \"\n",
    "                                                              + \"workflow directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pipeline.py` activates the DataJoint `elements` and declares other required tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "from workflow_deeplabcut.pipeline import lab, subject, session, train, model\n",
    "\n",
    "# Directing our pipeline to the appropriate config location\n",
    "from element_interface.utils import find_full_path\n",
    "from workflow_deeplabcut.paths import get_dlc_root_data_dir\n",
    "config_path = find_full_path(get_dlc_root_data_dir(), \n",
    "                             'from_top_tracking/config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Manually Inserting Entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upstream tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can insert entries into `dj.Manual` tables (green in diagrams) by providing values as a dictionary or a list of dictionaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.Session.heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.Subject.insert1(dict(subject='subject6', \n",
    "                             sex='F', \n",
    "                             subject_birth_date='2020-01-01', \n",
    "                             subject_description='hneih_E105'))\n",
    "session_keys = [dict(subject='subject6', session_datetime='2021-06-02 14:04:22'),\n",
    "                dict(subject='subject6', session_datetime='2021-06-03 14:43:10')]\n",
    "session.Session.insert(session_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the contents of this table and restrict by a value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.Session() & \"session_datetime > '2021-06-01 12:00:00'\" & \"subject='subject6'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### DeepLabcut Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `VideoSet` table in the `train` schema retains records of files generated in the video labeling process (e.g., `h5`, `csv`, `png`). DeepLabCut will refer to the `mat` file located under the `training-datasets` directory.\n",
    "\n",
    "We recommend storing all paths as relative to the root in your config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.VideoSet.insert1({'video_set_id': 0})\n",
    "project_folder = 'from_top_tracking/'\n",
    "training_files = ['labeled-data/train1/CollectedData_DJ.h5',\n",
    "                  'labeled-data/train1/CollectedData_DJ.csv',\n",
    "                  'labeled-data/train1/img00674.png',\n",
    "                  'videos/train1.mp4']\n",
    "for idx, filename in enumerate(training_files):\n",
    "    train.VideoSet.File.insert1({'video_set_id': 0,\n",
    "                                 'file_id': idx,\n",
    "                                 'file_path': (project_folder + filename)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.VideoSet.File()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training a Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll add a `ModelTrainingParamSet`. This is a lookup table that we can reference when training a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.TrainingParamSet.heading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `params` longblob should be a dictionary that captures all items for DeepLabCut's `train_network` function. At minimum, this is the contents of the project's config file, as well as `suffle` and `trainingsetindex`, which are not included in the config. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplabcut import train_network\n",
    "help(train_network) # for more information on optional parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we give these items, load the config contents, and overwrite some defaults, including `maxiters`, to restrict our training iterations to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "paramset_idx = 0; paramset_desc='from_top_tracking'\n",
    "\n",
    "with open(config_path, 'rb') as y:\n",
    "    config_params = yaml.safe_load(y)\n",
    "training_params = {'shuffle': '1',\n",
    "                   'trainingsetindex': '0',\n",
    "                   'maxiters': '5',\n",
    "                   'scorer_legacy': 'False',\n",
    "                   'maxiters': '5', \n",
    "                   'multianimalproject':'False'}\n",
    "config_params.update(training_params)\n",
    "train.TrainingParamSet.insert_new_params(paramset_idx=paramset_idx,\n",
    "                                         paramset_desc=paramset_desc,\n",
    "                                         params=config_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we add a `TrainingTask`. As a computed table, `ModelTraining` will reference this to start training when calling `populate()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.TrainingTask.heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key={'video_set_id': 0,\n",
    "     'paramset_idx':0,\n",
    "     'training_id': 1,\n",
    "     'project_path':'from_top_tracking/'\n",
    "     }\n",
    "train.TrainingTask.insert1(key, skip_duplicates=True)\n",
    "train.TrainingTask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.ModelTraining.populate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Output cleared for brevity)\n",
    "```\n",
    "The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.ModelTraining()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To resume training from a checkpoint, we would need to \n",
    "[edit the relevant config file](https://github.com/DeepLabCut/DeepLabCut/issues/70) (see also `update_pose_cfg` in `workflow_deeplabcut.load_demo_data`).\n",
    "Emperical work suggests 200k iterations for any true use-case.\n",
    "\n",
    "For better quality predictions in this demo, we'll revert the checkpoint file and use a pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow_deeplabcut.load_demo_data import revert_checkpoint_file\n",
    "revert_checkpoint_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tracking Joints/Body Parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `model` schema uses a lookup table for managing Body Parts tracked across models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.BodyPart.heading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions allow us to first, identify all the new body parts from a given config, and, second, insert them with user-friendly descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.BodyPart.extract_new_body_parts(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_desc=['Body Center', 'Head', 'Base of Tail']\n",
    "model.BodyPart.insert_from_config(config_path,bp_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Declaring/Evaluating a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can insert into `Model` table for automatic evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Model.insert_new_model(model_name='FromTop-latest',dlc_config=config_path,\n",
    "                             shuffle=1,trainingsetindex=0,\n",
    "                             model_description='FromTop - latest snapshot',\n",
    "                             paramset_idx=0,\n",
    "                             params={\"snapshotindex\":-1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ModelEvaluation` will reference the `Model` using the `populate` method and insert the  output from DeepLabCut's `evaluate_network` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ModelEvaluation.heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ModelEvaluation.populate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ModelEvaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use our model, we'll first need to insert a session recoring into `VideoRecording`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.VideoRecording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = {'subject': 'subject6',\n",
    "       'session_datetime': '2021-06-02 14:04:22',\n",
    "       'recording_id': '1', 'device': 'Camera1'}\n",
    "model.VideoRecording.insert1(key)\n",
    "\n",
    "_ = key.pop('device') # get rid of secondary key from master table\n",
    "key.update({'file_id': 1, \n",
    "            'file_path': 'from_top_tracking/videos/test-2s.mp4'})\n",
    "model.VideoRecording.File.insert1(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.VideoRecording.File()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RecordingInfo` automatically populates with file information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.RecordingInfo.populate()\n",
    "model.RecordingInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we specify if the `PoseEstimation` table should load results from an existing file or trigger the estimation command. Here, we can also specify parameters for DeepLabCut's `analyze_videos` as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = (model.VideoRecording & {'recording_id': '1'}).fetch1('KEY')\n",
    "key.update({'model_name': 'FromTop-latest', 'task_mode': 'trigger'})\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.PoseEstimationTask.insert_estimation_task(key,params={'save_as_csv':True})\n",
    "model.PoseEstimation.populate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, DataJoint will store results in a subdirectory\n",
    ">       <processed_dir> / videos / device_<name>_recording_<#>_model_<name>\n",
    "where `processed_dir` is optionally specified in the datajoint config. If unspecified, this will be the project directory. The device and model names are specified elsewhere in the schema.\n",
    "\n",
    "We can get this estimation directly as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.PoseEstimation.get_trajectory(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [next notebook](./04-Automate_Optional.ipynb), we'll look at additional tools in the workflow for automating these steps."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ele')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "d00c4ad21a7027bf1726d6ae3a9a6ef39c8838928eca5a3d5f51f3eb68720410"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
